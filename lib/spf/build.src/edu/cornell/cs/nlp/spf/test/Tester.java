/*******************************************************************************
 * Copyright (C) 2011 - 2015 Yoav Artzi, All rights reserved.
 * <p>
 * This program is free software; you can redistribute it and/or modify it under
 * the terms of the GNU General Public License as published by the Free Software
 * Foundation; either version 2 of the License, or any later version.
 * <p>
 * This program is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
 * FOR A PARTICULAR PURPOSE. See the GNU General Public License for more
 * details.
 * <p>
 * You should have received a copy of the GNU General Public License along with
 * this program; if not, write to the Free Software Foundation, Inc., 51
 * Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
 *******************************************************************************/
package edu.cornell.cs.nlp.spf.test;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

import edu.cornell.cs.nlp.spf.base.hashvector.IHashVector;
import edu.cornell.cs.nlp.spf.ccg.lexicon.LexicalEntry;
import edu.cornell.cs.nlp.spf.data.IDataItem;
import edu.cornell.cs.nlp.spf.data.ILabeledDataItem;
import edu.cornell.cs.nlp.spf.data.collection.IDataCollection;
import edu.cornell.cs.nlp.spf.explat.IResourceRepository;
import edu.cornell.cs.nlp.spf.explat.ParameterizedExperiment.Parameters;
import edu.cornell.cs.nlp.spf.explat.resources.IResourceObjectCreator;
import edu.cornell.cs.nlp.spf.explat.resources.usage.ResourceUsage;
import edu.cornell.cs.nlp.spf.mr.lambda.ExtractExpressions;
import edu.cornell.cs.nlp.spf.mr.lambda.LogicLanguageServices;
import edu.cornell.cs.nlp.spf.mr.lambda.LogicalExpression;
import edu.cornell.cs.nlp.spf.parser.IDerivation;
import edu.cornell.cs.nlp.spf.parser.IOutputLogger;
import edu.cornell.cs.nlp.spf.parser.IParser;
import edu.cornell.cs.nlp.spf.parser.IParserOutput;
import edu.cornell.cs.nlp.spf.parser.ccg.IWeightedParseStep;
import edu.cornell.cs.nlp.spf.parser.ccg.model.IDataItemModel;
import edu.cornell.cs.nlp.spf.parser.ccg.model.IModelImmutable;
import edu.cornell.cs.nlp.spf.test.stats.ITestingStatistics;
import edu.cornell.cs.nlp.utils.collections.ListUtils;
import edu.cornell.cs.nlp.utils.filter.IFilter;
import edu.cornell.cs.nlp.utils.log.ILogger;
import edu.cornell.cs.nlp.utils.log.LoggerFactory;
import javafx.util.Pair;

/**
 * Testing procedure. This tester is insensitive to the syntactic category
 * generated by inference procedure and only evaluated the semantic component.
 *
 * @author Yoav Artzi
 * @param <SAMPLE>
 *            Inference data item.
 * @param <MR>
 *            Meaning representation.
 * @param <DI>
 *            Labeled data item.
 */
public class Tester<SAMPLE extends IDataItem<?>, MR, DI extends ILabeledDataItem<SAMPLE, MR>>
		implements ITester<SAMPLE, MR, DI> {

	public static final ILogger LOG = LoggerFactory
			.create(Tester.class.getName());

	private final IOutputLogger<MR> outputLogger;

	private final IParser<SAMPLE, MR> parser;

	private final IFilter<SAMPLE> skipParsingFilter;

	private final IDataCollection<? extends DI> testData;
	
	private final int allowableCost;
	
	/** -- added by Candace --
	 * this is used for trends data file
	 */
	private final String parentDirectory;
	
	private final List<String> types = new ArrayList<String>();

	private Tester(IDataCollection<? extends DI> testData,
			IFilter<SAMPLE> skipParsingFilter, IParser<SAMPLE, MR> parser,
			IOutputLogger<MR> outputLogger, String parentDirectory) {
		this.testData = testData;
		this.skipParsingFilter = skipParsingFilter;
		this.parser = parser;
		this.outputLogger = outputLogger;
		this.parentDirectory = parentDirectory; // added by Candace
		
		// TODO get as param
		this.allowableCost = 2;
		
		// TODO eventually allow for updating types
		for (String s : LogicLanguageServices.getTypeRepository().toString().split("\n")){
			types.add(s.replaceAll("\\s.*", ""));
		}
				
		LOG.info("Init Tester:  testData.size()=%d", testData.size());
	}

	@Override
	public void test(IModelImmutable<SAMPLE, MR> model,
			ITestingStatistics<SAMPLE, MR, DI> stats) {
		test(testData, model, stats);
	}

	private void logDerivation(IDerivation<MR> derivation,
			IDataItemModel<MR> dataItemModel) {
		LOG.info("[%.2f] %s", derivation.getScore(), derivation);
		for (final IWeightedParseStep<MR> step : derivation.getMaxSteps()) {
			LOG.info("\t%s",
					step.toString(false, false, dataItemModel.getTheta()));
		}
	}

	private void logParse(ILabeledDataItem<SAMPLE, MR> dataItem,
			IDerivation<MR> parse, boolean logLexicalItems, String tag,
			IModelImmutable<SAMPLE, MR> model) {
		LOG.info("%s%s[S%.2f] %s",
				dataItem.getLabel().equals(parse.getCategory()) ? "* " : "  ",
				tag == null ? "" : tag + " ", parse.getScore(), parse);
		LOG.info("Calculated score: %f",
				model.score(parse.getAverageMaxFeatureVector()));
		LOG.info("Features: %s", model.getTheta()
				.printValues(parse.getAverageMaxFeatureVector()));
		if (logLexicalItems) {
			for (final LexicalEntry<MR> entry : parse.getMaxLexicalEntries()) {
				LOG.info("\t[%f] %s", model.score(entry), entry);
			}
		}
	}
	
	private final int costPerPredicate(String predicate){
		return 1;
	}
	
	private final int dist(List<String> goldExpressions, List<String> predictedExpressions){
			if (goldExpressions.isEmpty()){
				Integer cost = 0;
				for (int i=0; i < predictedExpressions.size(); i++){
					cost += costPerPredicate(predictedExpressions.get(i));
				}
				return cost;
			} else if (predictedExpressions.isEmpty()){
				Integer cost = 0;
				for (int i=0; i < goldExpressions.size(); i++){
					cost += costPerPredicate(goldExpressions.get(i));
				}
				return cost;
			
		} else{
			List<Integer> costs = new ArrayList<Integer>();
			costs.add(dist(goldExpressions.subList(1, goldExpressions.size()), predictedExpressions)
							+ costPerPredicate(goldExpressions.get(0)));
			costs.add(dist(goldExpressions, predictedExpressions.subList(1, predictedExpressions.size()))
							+ costPerPredicate(predictedExpressions.get(0)));
			costs.add(dist(goldExpressions.subList(1, goldExpressions.size()), predictedExpressions.subList(1, predictedExpressions.size()))
							+ (goldExpressions.get(0).equals(predictedExpressions.get(0)) ?
												0 :
												(costPerPredicate(goldExpressions.get(0)) + costPerPredicate(predictedExpressions.get(0)))));
			return Collections.min(costs);
		}
	}
	

	private boolean isParseCorrect(final DI dataItem, MR label, boolean partialMatch){
		if (dataItem.isCorrect(label)){
			return true;
		}
		// check for near misses
		Pair<List<String>, List<String>> extracted = ExtractExpressions.extract((LogicalExpression) label);
		List<String> hypothesisLiteralExpressions = extracted.getValue();
		
		
		// ----------- run comparison ---------//
		// return immediately if hypothesis expression is any of permutations
		if (dataItem.getRenamedExpressions().contains(hypothesisLiteralExpressions)){
			return true;
		}

		if (partialMatch){
		    // TODO
		    if (dataItem.getSample().toString().split(" ").length > 12){
			return false;
		    }
							
		    for (int p=0; p < dataItem.getRenamedExpressions().size(); p++){
			Integer cost = dist(dataItem.getRenamedExpressions().get(p),
					    hypothesisLiteralExpressions);
			
			if (cost <= allowableCost) {
			    return true;
			}
		    }
		}
		
		return false;
	}
	
	private void processSingleBestParse(final DI dataItem,
			IDataItemModel<MR> dataItemModel,
			final IParserOutput<MR> modelParserOutput,
			final IDerivation<MR> parse, boolean withWordSkipping,
			ITestingStatistics<SAMPLE, MR, DI> stats) {
		final MR label = parse.getSemantics();

		// Update statistics
		boolean isCorrect = isParseCorrect(dataItem, label, false);
		boolean isCorrectPartialMatch = isParseCorrect(dataItem, label, true);
		
		if (withWordSkipping) {
		        stats.recordParse(dataItem, parse.getSemantics(), isCorrect);
			stats.recordParseWithSkipping(dataItem, parse.getSemantics());
			stats.recordParsePartialMatch(dataItem, parse.getSemantics(), isCorrectPartialMatch);
		} else {
			stats.recordParse(dataItem, parse.getSemantics(), isCorrect);
			stats.recordParsePartialMatch(dataItem, parse.getSemantics(), isCorrectPartialMatch);
		}
	
		if (isCorrect){
			// A correct parse
			LOG.info("CORRECT");
			logDerivation(parse, dataItemModel);
			LOG.info("Had correct parses: true");
		} else {
			// One parse, but a wrong one
			LOG.info("WRONG", label);
			logDerivation(parse, dataItemModel);
			
			
			// Check if we had the correct parse and it just wasn't the best
			// Also check if we had a correct partial parse that just wasn't the best
			final List<? extends IDerivation<MR>> correctParses =
						modelParserOutput.getMaxDerivations(e -> isParseCorrect(dataItem, e.getSemantics(), false));
			final List<? extends IDerivation<MR>> correctParsesPartialMatch =
					modelParserOutput.getMaxDerivations(e -> isParseCorrect(dataItem, e.getSemantics(), true));
			
			
			LOG.info("Had correct parses: %s", !correctParses.isEmpty());
			LOG.info("Had correct parses with partial match: %s", !correctParsesPartialMatch.isEmpty());
			
			if (!correctParses.isEmpty()) {				
				for (final IDerivation<MR> correctParse : correctParses) {
					LOG.info("Correct derivation:");
					logDerivation(correctParse, dataItemModel);
					
					final IHashVector diff = correctParse
							.getAverageMaxFeatureVector()
							.addTimes(-1.0, parse.getAverageMaxFeatureVector());
					diff.dropNoise();
					LOG.info("Diff: %s",
							dataItemModel.getTheta().printValues(diff));
				}
			}
			if (correctParsesPartialMatch.isEmpty()) {
				for (final IDerivation<MR> correctParsePartialMatch : correctParsesPartialMatch) {
					LOG.info("Correct derivation with partial match:");
					logDerivation(correctParsePartialMatch, dataItemModel);
					
					final IHashVector diff = correctParsePartialMatch
							.getAverageMaxFeatureVector()
							.addTimes(-1.0, parse.getAverageMaxFeatureVector());
					diff.dropNoise();
					LOG.info("Diff: %s",
							dataItemModel.getTheta().printValues(diff));
				}
			}
			
			LOG.info("Feats: %s", dataItemModel.getTheta()
					.printValues(parse.getAverageMaxFeatureVector()));
		}
	}

	private void test(IDataCollection<? extends DI> dataset,
			IModelImmutable<SAMPLE, MR> model,
			ITestingStatistics<SAMPLE, MR, DI> stats) {
		System.out.println("=========================");
		System.out.println("Start of test");
		System.out.println("=========================");
		
		int itemCounter = 0;
		for (final DI item : dataset) {	
			if (itemCounter % 25 == 0){
				System.out.println("testing data item " + itemCounter + " of " + dataset.size());
			}
			++itemCounter;
			test(itemCounter, item, model, stats);
		}
		/** --added by Candace
		 * for averages across training data
		 */
		stats.writeAveragesToFile(String.format("%s/logs/trends_test.txt", parentDirectory), dataset.size());
		stats.writeFinalAccuracy(String.format("%s/logs/final_accuracy_test.txt", this.parentDirectory));
	}

	private void test(int itemCounter, final DI dataItem,
			IModelImmutable<SAMPLE, MR> model,
			ITestingStatistics<SAMPLE, MR, DI> stats) {
		LOG.info("%d : ==================", itemCounter);
		LOG.info("%s", dataItem);

		final IDataItemModel<MR> dataItemModel = model
				.createDataItemModel(dataItem.getSample());

		// Try a simple model parse
		final IParserOutput<MR> modelParserOutput = parser
				.parse(dataItem.getSample(), dataItemModel);
		LOG.info("Test parsing time %.2fsec",
				modelParserOutput.getParsingTime() / 1000.0);
		outputLogger.log(modelParserOutput, dataItemModel,
				String.format("test-%d", itemCounter));
		
		// TODO is this including partial parses?
		final List<? extends IDerivation<MR>> bestModelParses = modelParserOutput.getBestDerivations();
		
		if (bestModelParses.size() == 1) {
			// Case we have a single parse
			processSingleBestParse(dataItem, dataItemModel, modelParserOutput,
					bestModelParses.get(0), false, stats);
		} else if (bestModelParses.size() > 1) {
			// Multiple top parses
			
			// Update statistics
			// TODO ADD partial
			stats.recordParses(dataItem,
					ListUtils.map(bestModelParses, obj -> obj.getSemantics()));

			// There are more than one equally high scoring
			// logical forms. If this is the case, we abstain
			// from returning a result.
			LOG.info("too many parses");
			LOG.info("%d parses:", bestModelParses.size());
			for (final IDerivation<MR> parse : bestModelParses) {
				logParse(dataItem, parse, false, null, model);
			}
			
			// Check if we had the correct parse and it just wasn't the best
			final List<? extends IDerivation<MR>> correctParses =
					modelParserOutput.getMaxDerivations( e -> isParseCorrect(dataItem, e.getSemantics(), false) );
			final List<? extends IDerivation<MR>> correctParsesPartialMatch =
					modelParserOutput.getMaxDerivations( e -> isParseCorrect(dataItem, e.getSemantics(), true) );
			
			
			LOG.info("Had correct parses: %s", !correctParses.isEmpty());
			LOG.info("Had correct parses with partialMatch: %s", !correctParsesPartialMatch.isEmpty());
			if (!correctParses.isEmpty()) {
				for (final IDerivation<MR> correctParse : correctParses) {
					logDerivation(correctParse, dataItemModel);
				}
			} else{
				for (final IDerivation<MR> correctParsePartialMatch : correctParsesPartialMatch) {
					logDerivation(correctParsePartialMatch, dataItemModel);
				}
			}
		}
		else {
			// No parses
			LOG.info("no parses");

			// Update stats
			stats.recordNoParse(dataItem);
			stats.recordNoParsePartialMatch(dataItem);
			stats.recordNoParseWithSkipping(dataItem);
			
			// Potentially re-parse with word skipping
			if (skipParsingFilter.test(dataItem.getSample())) {
				final IParserOutput<MR> parserOutputWithSkipping = parser
						.parse(dataItem.getSample(), dataItemModel, true);
				LOG.info("EMPTY Parsing time %fsec",
						parserOutputWithSkipping.getParsingTime() / 1000.0);
				outputLogger.log(parserOutputWithSkipping, dataItemModel,
						String.format("test-%d-sloppy", itemCounter));
				final List<? extends IDerivation<MR>> bestEmptiesParses = parserOutputWithSkipping
						.getBestDerivations();

				if (bestEmptiesParses.size() == 1) {
					processSingleBestParse(dataItem, dataItemModel,
							parserOutputWithSkipping, bestEmptiesParses.get(0),
							true, stats);
				} else if (bestEmptiesParses.isEmpty()) {
					// No parses
					LOG.info("no parses");

					stats.recordNoParse(dataItem);
					stats.recordNoParseWithSkipping(dataItem);
					stats.recordNoParsePartialMatch(dataItem);
				} else {
					// too many parses or no parses
				        stats.recordNoParse(dataItem);
					stats.recordNoParsePartialMatch(dataItem);
					stats.recordParsesWithSkipping(dataItem, ListUtils
							.map(bestEmptiesParses, obj -> obj.getSemantics()));

					LOG.info("WRONG: %d parses", bestEmptiesParses.size());
					for (final IDerivation<MR> parse : bestEmptiesParses) {
						logParse(dataItem, parse, false, null, model);
					}
					// Check if we had the correct parse and it just wasn't the best
					final List<? extends IDerivation<MR>> correctParses =
							parserOutputWithSkipping.getMaxDerivations(e -> isParseCorrect(dataItem, e.getSemantics(), false));
					final List<? extends IDerivation<MR>> correctParsesPartialMatch =
							parserOutputWithSkipping.getMaxDerivations(e -> isParseCorrect(dataItem, e.getSemantics(), true));
					
					LOG.info("Had correct parses: %s",
							!correctParses.isEmpty());
					LOG.info("Had correct parses with partial match: %s",
							!correctParses.isEmpty());
					if (!correctParses.isEmpty()) {
						for (final IDerivation<MR> correctParse : correctParses) {
							logDerivation(correctParse, dataItemModel);
						}
					} else{
						for (final IDerivation<MR> correctParsePartialMatch : correctParsesPartialMatch) {
							logDerivation(correctParsePartialMatch, dataItemModel);
						}
					}
				}
			} else {
				LOG.info("Skipping word-skip parsing due to length");
				stats.recordNoParse(dataItem);
				stats.recordNoParseWithSkipping(dataItem);
				stats.recordNoParsePartialMatch(dataItem);
			}
		}
	}
	
	
	public static class Builder<SAMPLE extends IDataItem<?>, MR, DI extends ILabeledDataItem<SAMPLE, MR>> {

		private IOutputLogger<MR> outputLogger = new IOutputLogger<MR>() {
			private static final long serialVersionUID = -2828347737693835555L;

			@Override
			public void log(IParserOutput<MR> output,
					IDataItemModel<MR> dataItemModel, String tag) {
				// Stub.
			}
		};

		private final IParser<SAMPLE, MR> parser;
		
		/**
		 * -- added by Candace --
		 */
		private String 									parentDirectory;

		/** Filters which data items are valid for parsing with word skipping */
		private IFilter<SAMPLE> skipParsingFilter = e -> true;

		private final IDataCollection<? extends DI> testData;

		public Builder(IDataCollection<? extends DI> testData,
				IParser<SAMPLE, MR> parser) {
			this.testData = testData;
			this.parser = parser;
		}

		public Tester<SAMPLE, MR, DI> build() {
			return new Tester<SAMPLE, MR, DI>(testData, skipParsingFilter,
					parser, outputLogger, parentDirectory);
		}

		public Builder<SAMPLE, MR, DI> setOutputLogger(
				IOutputLogger<MR> outputLogger) {
			this.outputLogger = outputLogger;
			return this;
		}

		public Builder<SAMPLE, MR, DI> setSkipParsingFilter(
				IFilter<SAMPLE> skipParsingFilter) {
			this.skipParsingFilter = skipParsingFilter;
			return this;
		}
		
		/**
		 * -- added by Candace --
		 */
		public Builder<SAMPLE, MR, DI> setParentDirectory(String parentDirectory) {
			this.parentDirectory = parentDirectory;
			return this;
		}
	}

	public static class Creator<SAMPLE extends IDataItem<?>, LABEL, DI extends ILabeledDataItem<SAMPLE, LABEL>>
			implements IResourceObjectCreator<Tester<SAMPLE, LABEL, DI>> {

		@SuppressWarnings("unchecked")
		@Override
		public Tester<SAMPLE, LABEL, DI> create(Parameters parameters,
				IResourceRepository resourceRepo) {

			// Get the testing set
			final IDataCollection<DI> testSet;
			{
				// [yoav] [17/10/2011] Store in Object to javac known bug
				final Object dataCollection = resourceRepo
						.get(parameters.get("data"));
				if (dataCollection == null
						|| !(dataCollection instanceof IDataCollection<?>)) {
					throw new RuntimeException(
							"Unknown or non labeled dataset: "
									+ parameters.get("data"));
				} else {
					testSet = (IDataCollection<DI>) dataCollection;
				}
			}
			
			if (!parameters.contains("parser")) {
				throw new IllegalStateException(
						"tester now requires you to provide a parser");
			}

			final Tester.Builder<SAMPLE, LABEL, DI> builder = new Tester.Builder<SAMPLE, LABEL, DI>(
					testSet, (IParser<SAMPLE, LABEL>) resourceRepo
							.get(parameters.get("parser")));

			if (parameters.get("skippingFilter") != null) {
				builder.setSkipParsingFilter((IFilter<SAMPLE>) resourceRepo
						.get(parameters.get("skippingFilter")));
			}
			
			/**
			 * -- added by Candace --
			 */
			builder.setParentDirectory(resourceRepo.get("parentDirectory"));
			
			return builder.build();
		}

		@Override
		public String type() {
			return "tester";
		}

		@Override
		public ResourceUsage usage() {
			return new ResourceUsage.Builder(type(), Tester.class)
					.setDescription(
							"Model tester. Tests inference using the model on some testing data")
					.addParam("data", "id",
							"IDataCollection that holds ILabaledDataItem entries")
					.addParam("parser", "id", "Parser object")
					.addParam("skippingFilter", "id",
							"IFilter used to decide which data items to skip")
					.build();
		}

	}

}
